{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Note: Before starting the slideshow, make sure you run this code as it\n",
    "# provides helper functions that the other slides need...\n",
    "#\n",
    "# Other than that, you can ignore this content as it won't show up in the slideshow.\n",
    "#\n",
    "# It's a helper function that makes it easier to show OpenCV images directly\n",
    "# in the notebook environment. When using OpenCV locally, you'll want to use\n",
    "# `cv2.imshow(name, img)` instead.\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# Notebook setup + convenience functions\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def force_bgr(img):\n",
    "    '''Forces image to 3-channel representation if grayscale'''\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    return img\n",
    "\n",
    "def imshow(*args):\n",
    "    '''Helper function to show images, because matplotlib and OpenCV aren't a perfect match'''\n",
    "    fig = plt.figure()\n",
    "    for i, img in enumerate(args):\n",
    "        fig.add_subplot(1,len(args),i+1)\n",
    "        plt.imshow(cv2.cvtColor(force_bgr(img), cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# <center>Image processing using</center>\n",
    "\n",
    "## <center>OpenCV + Python + mjpg-streamer</center>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<center>Dustin Spicuzza (Team 2423/1418)</center>\n",
    "<br/>\n",
    "<center>September 10, 2016</center>\n",
    "<br/>\n",
    "<center><span style=\"color: #ababab\">NE FIRST University Day</span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "\n",
    "* Why OpenCV + Python?\n",
    "* Image filtering demo\n",
    "* pynetworktables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Image processing\n",
    "\n",
    "* FRC Teams do it a lot of ways\n",
    "    * NIVision (LabVIEW)\n",
    "    * GRIP (Uses OpenCV as engine)\n",
    "    * OpenCV (various custom stuff)\n",
    "    \n",
    "* We're going to talk about OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why OpenCV?\n",
    "\n",
    "* Originally developed by Intel\n",
    "* It has thousands of image processing related algorithms and functions available\n",
    "  * Highly optimized and reliable\n",
    "  * Has building blocks that fit together\n",
    "* Lets you do complex image processing without needing to understand the math\n",
    "  * If you understand the math, it helps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why OpenCV?\n",
    "\n",
    "* Bindings for multiple languages\n",
    "    * C/C++\n",
    "    * Java\n",
    "    * Python\n",
    "* Multiple platforms supported\n",
    "    * Windows\n",
    "    * Linux\n",
    "    * OSX\n",
    "    * Android\n",
    "* Oh, and it’s **FREE**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What OpenCV Provides\n",
    "\n",
    "* Image I/O:\n",
    "    * Read/Write images from disk\n",
    "    * Use native OS functionality to interface with cameras\n",
    "* Image Segmentation\n",
    "    * Edge finding\n",
    "    * Contour detection\n",
    "    * Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What OpenCV Provides\n",
    "\n",
    "* Face detection\n",
    "* Motion tracking\n",
    "* Stereo vision support\n",
    "* Support for GPU acceleration\n",
    "* Machine learning operations\n",
    "    * Classifiers\n",
    "    * Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What OpenCV Provides\n",
    "\n",
    "* Distributed with lots of useful samples that you can use to figure out how OpenCV works\n",
    "    * Face detection\n",
    "    * Edge finding\n",
    "    * Histograms\n",
    "    * Square finder\n",
    "\n",
    "Lots and lots and lots of stuff… "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Python + OpenCV?\n",
    "\n",
    "* Python is really easy to learn and use\n",
    "    * Simple syntax\n",
    "    * Rapid prototyping\n",
    "* Most of the compute intensive work is implemented in C/C++\n",
    "    * Python is just glue, realtime operation **is** possible\n",
    "* NumPy is awesome\n",
    "    * Manipulating image data is trivial compared to other OpenCV bindings (Java, C++)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Time to CODE!</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Go to http://goo.gl/nB0NCG</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About this environment\n",
    "\n",
    "http://goo.gl/nB0NCG\n",
    "\n",
    "* It's a Jupyter Notebook (formerly IPython Notebook)\n",
    "    * This slideshow uses Jupyter too!\n",
    "    \n",
    "* It allows you to mix text and executable code in a webpage\n",
    "* You execute each cell using SHIFT-ENTER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hello World!\n",
    "\n",
    "* Click the cell with the following text, and press SHIFT-ENTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Hello class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Next Steps\n",
    "\n",
    "* Execute the helper code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The next cell tells you about the images available in your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%ls images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hello image!\n",
    "\n",
    "* Let's load an image and show it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Change this to load different images\n",
    "img = cv2.imread('images/2016-cmp-5.jpg')\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hello image!\n",
    "\n",
    "* You can show multiple images next to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imshow(img, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenCV Image Basics\n",
    "\n",
    "* Images are stored as multidimensional arrays\n",
    "    * Color images have 3 dimensions: height, width, channel\n",
    "* Each pixel is a number stored in the array\n",
    "* Numpy array notation allows you to do operations on individual pixels or ranges of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img[50, 150, :]           # Access a single pixel,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = img[24:42, 42:100, :]    # Access a range of pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenCV Image Basics\n",
    "\n",
    "* Color is represented by storing combinations of Red, Blue, and Green pixels in separate channels\n",
    "    * OpenCV uses BGR representation, not RGB\n",
    "* The amount of each individual color is represented in the individual channel\n",
    "    * ‘dark’ is zero, ‘bright’ is 255\n",
    "* Combine the channels to represent a color\n",
    "    * Green = RGB( 0, 255, 0 )\n",
    "    * Deep Pink = RGB( 255, 20, 147 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenCV Image Basics\n",
    "\n",
    "* Using numpy we can easily fill an image with a single color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# define image with height=240, width=320, 3 channels\n",
    "shape = (240, 320, 3)\n",
    "pink_img = np.empty(shape, dtype=np.uint8)\n",
    "\n",
    "# Fill every pixel with a single color\n",
    "pink_img[:] = (0, 255, 0)\n",
    "\n",
    "imshow(pink_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical Example\n",
    "\n",
    "* 2016 FIRST Stronghold: find targets that are surrounded by retroreflective tape, and shoot boulders into them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical Example\n",
    "* Finding gray tape at a distance isn’t particularly easy\n",
    "    * Key part of image processing is removing as much non-essential information from image \n",
    "* We can do better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Retroreflective Tape\n",
    "\n",
    "* It has a useful property -- it reflects light directly back at the source\n",
    "* What can we do with this property?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Shine bright LEDs at the target and the tape reflects that color back to the camera\n",
    "    * Many teams have found that green light works best\n",
    "* Reduce exposure of camera so only bright light sources are seen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A note about exposure\n",
    "\n",
    "* Webcams support setting the exposure manually (yay)\n",
    "* Some cameras only allow particular exposure settings \n",
    "    * The lifecam is one of them\n",
    "* OpenCV has bugs, it doesn't set the exposure properly\n",
    "* Here's a workaround that works on linux:\n",
    "\n",
    "```sh \n",
    "v4l2-ctl -d /dev/video0 -c exposure_auto=1 -c exposure_absolute=10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Retroreflective Tape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread('images/2016-p0.jpg')\n",
    "img2 = cv2.imread('images/2016-p1.jpg')\n",
    "imshow(img1, img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical Example\n",
    "\n",
    "Processing steps to find targets:\n",
    "\n",
    "* Isolate the green portions of the image\n",
    "* Analyze the green portions to determine targets\n",
    "\n",
    "**Note**: There are a lot of ways to go about this, I'm just showing you one way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "* What is “green” anyways?\n",
    "    * <span style=\"color: green\">This is green.</span> <span style=\"color: darkgreen\">This is also green.</span>\n",
    "* To a computer, green is really a range of colors\n",
    "* An object’s color changes depending on lighting conditions\n",
    "* We can transform the image to identify colors independent of lighting conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "* Convert the image from RGB to HSV\n",
    "    * Hue: the color\n",
    "    * Saturation: Colorfulness\n",
    "    * Value: Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "imshow(img, hsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "That doesn't show why HSV is useful. Let's look at the individual channels instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "h, s, v = cv2.split(hsv)\n",
    "imshow(h, s, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "* Green is a range of values present in the image\n",
    "* ‘Threshold’ the image to get rid of the colors that we don’t care about\n",
    "* Lots of ways to do this\n",
    "    * Manually specify values\n",
    "    * Automated methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "`cv2.inRange` can threshold an image given two ranges of pixels.\n",
    "* Wanted values are converted to 255\n",
    "* Unwanted values are now 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "lower = np.array([0, 145, 80])\n",
    "upper = np.array([255, 255, 255])\n",
    "\n",
    "filtered = cv2.inRange(hsv, lower, upper)\n",
    "imshow(img, filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "Sometimes, you end up with holes in your output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img3 = cv2.imread('images/2013-f0.png')\n",
    "hsv3 = cv2.cvtColor(img3, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Thresholds are different because different camera/lighting\n",
    "lower3 = np.array([30, 188, 16])\n",
    "upper3 = np.array([75, 255, 255])\n",
    "filtered3 = cv2.inRange(hsv3, lower3, upper3)\n",
    "imshow(filtered3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identify the green\n",
    "\n",
    "* We can use a morphological operation to fill in the holes\n",
    "    * Various types of morphology operations available\n",
    "* They modify a pixel based on the values of its neighboring pixels\n",
    "    * The one we use to fill in holes is a “closing” operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2,2), anchor=(1,1))\n",
    "output = cv2.morphologyEx(filtered3, cv2.MORPH_CLOSE, kernel,\n",
    "                          iterations=9)\n",
    "imshow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identifying Targets\n",
    "\n",
    "Use `findContours()` to find regions of interest\n",
    "* Returns a list of points bounding each separate blob in the image (called a contour)\n",
    "* Also returns a hierarchy so you can determine whether a contour is entirely inside another contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "image, contours, hierarchy = cv2.findContours(filtered,\n",
    "                                              cv2.RETR_LIST,\n",
    "                                              cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identifying Targets\n",
    "\n",
    "If you want to see what it found, you can draw the found contours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dst = np.zeros(shape=img.shape, dtype=img.dtype)\n",
    "cv2.drawContours(dst, contours, -1, (0, 255, 255), 1)\n",
    "imshow(dst)\n",
    "#print(contours[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identifying Targets\n",
    "\n",
    "* As you can see, contours aren't the whole story\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identifying Targets\n",
    "\n",
    "* Contour analysis\n",
    "    * Discard non-convex contours\n",
    "    * Convert to polygon approximation (approxPolyDP)\n",
    "    * Discard polygons that aren’t rectangles\n",
    "    * Discard polygons that aren't the right size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Magic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "min_width = 20 # in pixels\n",
    "results = []\n",
    "\n",
    "# Iterate over each contour\n",
    "for c in contours:\n",
    "    \n",
    "    # Contours are jagged lines -- smooth it out using an approximation\n",
    "    a1 = cv2.approxPolyDP(c, 0.01*cv2.arcLength(c, True), True)\n",
    "    \n",
    "    # This fills in the contour so that it's a rectangle\n",
    "    hull = cv2.convexHull(c)\n",
    "    \n",
    "    # Approximate the points again, smoothing out the hull\n",
    "    a2 = cv2.approxPolyDP(hull, 0.01*cv2.arcLength(hull, True), True)\n",
    "    \n",
    "    # We only care about objects that are wider than they are tall, and things wider\n",
    "    # than a particular width. Only keep things that meet that criteria.\n",
    "    _, _, w, h = cv2.boundingRect(a2)\n",
    "    if w > h and w > min_width and len(a2) in (4,5):\n",
    "        results.append(a2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Magic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, draw out our results\n",
    "dst = np.zeros(shape=img.shape, dtype=img.dtype)\n",
    "cv2.drawContours(dst, results, -1, (0, 0, 255), 1)\n",
    "imshow(dst)\n",
    "#print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identifying Targets\n",
    "\n",
    "* Sometimes you need to do more work\n",
    "    * Use ratios to determine which target you're looking at\n",
    "    * Remove duplicates (inner rectangles)\n",
    "    * Other types of validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now what?\n",
    "\n",
    "We have targets... probably should do something with them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Calculate angle/distance to target\n",
    "\n",
    "* I'm not a math guy, but this sorta works\n",
    "    * Angle works, distance is a bit iffy\n",
    "* Get the minimum bounding rectangle\n",
    "* Figure out the horizontal and vertical field of view for your camera\n",
    "    * Look it up online\n",
    "* Do math to it\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Just do the first one for now\n",
    "result = results[0]\n",
    "\n",
    "# Get the height/width\n",
    "h = float(img.shape[0])\n",
    "w = float(img.shape[1])\n",
    "\n",
    "# Define HFOV and VFOV\n",
    "VFOV = 45.6 # degrees\n",
    "HFOV = 61.0 # degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "((cx, cy), (rw, rh), rotation) = cv2.minAreaRect(result)\n",
    "\n",
    "# These work fairly well\n",
    "angle = VFOV * cy / h - (VFOV/2.0) \n",
    "height = HFOV * cx / w - (HFOV/2.0)\n",
    "\n",
    "print(angle, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# This is magic, but it doesn't really work\n",
    "target_height = 7.66 # 7' 8\"\n",
    "camera_height = 1.08 # 13\"\n",
    "camera_pitch = 40.0  # What angle is the camera at?\n",
    "t = (target_height - camera_height)\n",
    "distance = t/math.tan(math.radians(-angle + camera_pitch))\n",
    "\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Now What?\n",
    "\n",
    "* Send data via NetworkTables\n",
    "\n",
    "* ... I forgot to write this slide. It's easy, I promise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to run the image processing\n",
    "\n",
    "* RoboRIO\n",
    "    * RoboRIO is relatively slow, OpenCV eats a lot of CPU\n",
    "        * Hint: Make the images small (320x240)\n",
    "    * Less hardware to deal with\n",
    "    * FIRST intends to install OpenCV by default in 2017\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to run the image processing\n",
    "\n",
    "* Driver Station\n",
    "    * Streaming images to OpenCV is possible\n",
    "        * Various latency bugs\n",
    "    * Latency is an issue here\n",
    "    * mDNS problems (hopefully will be resolved in 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where to run the image processing\n",
    "\n",
    "* Coprocessor (Jetson, Raspberry PI, Nexus 5)\n",
    "    * Lots of teams do this\n",
    "    * More hardware to deal with\n",
    "    * Potentially higher fidelity processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mjpg-streamer\n",
    "\n",
    "* Open Source application for streaming Webcam over HTTP\n",
    "* Allows accessing camera stream from a webpage\n",
    "* Very little CPU usage if no image processing happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mjpg-streamer\n",
    "\n",
    "* I created an OpenCV plugin for it\n",
    "* You can provide python processing code:\n",
    "\n",
    "```python\n",
    "\n",
    "class MyFilter:\n",
    "    def process(self, img):\n",
    "        pass\n",
    "\n",
    "def init_filter():\n",
    " \n",
    "    f = MyFilter()\n",
    "    return f.process\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mjpg-streamer\n",
    "\n",
    "* I would show you a demo here, but my RoboRIO's USB is toasted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# mjpg-streamer\n",
    "\n",
    "* Peter Johnson is working on a better FRC-specific version of this\n",
    "* Expect to see it in 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Want code?\n",
    "\n",
    "* Working OpenCV code integrated with mjpg-streamer\n",
    "    * https://github.com/frc2423/2016/tree/master/OpenCV\n",
    "    * Includes code for storing images onto USB drive during matches\n",
    "    * Don't let our robot's performance fool you... :(\n",
    "    \n",
    "* The stuff we did here will be available sometime tonight\n",
    "    * https://github.com/virtuald/frc-imageprocessing-workshop-2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# If you want more\n",
    "\n",
    "* Team 254 gave an excellent presentation at CMP in 2016\n",
    "    * https://goo.gl/mppi4E\n",
    "    * Video/audio: http://www.chiefdelphi.com/forums/showthread.php?t=147568&page=3\n",
    "    * Latency compensation is an excellent technique presented here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "* Python 3.5.x\n",
    "    * https://www.python.org/downloads/\n",
    "* Learn Python\n",
    "    * http://www.codecademy.com/tracks/python\n",
    "\n",
    "* OpenCV 3.1.0\n",
    "    * http://opencv.org\n",
    "\n",
    "* NumPy\n",
    "    * Official site: http://www.numpy.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "* roborio-packages\n",
    "    * https://github.com/robotpy/roborio-packages\n",
    "* OpenCV for RoboRIO\n",
    "    * https://github.com/robotpy/roborio-opencv\n",
    "* mjpg-streamer for RoboRIO\n",
    "    * https://github.com/robotpy/mjpg-streamer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Resources\n",
    "\n",
    "* pynetworktables\n",
    "    * source code + examples @\n",
    "      https://github.com/robotpy/pynetworktables\n",
    "\n",
    "* Edit & debug python code using Eclipse\n",
    "    * Pydev: http://pydev.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# One more thing...\n",
    "\n",
    "FIRSTwiki: https://firstwiki.github.io\n",
    "\n",
    "* Publicly editable repository of information related to FIRST Robotics\n",
    "    * Technical topics\n",
    "    * Non-technical\n",
    "    * Team pages\n",
    "* Add content to your team’s page!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Questions?</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
